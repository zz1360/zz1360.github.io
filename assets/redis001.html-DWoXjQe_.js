import{_ as i,c as a,o as d,a as s}from"./app-DukR-6js.js";const r={};function n(t,e){return d(),a("div",null,e[0]||(e[0]=[s(`<h2 id="redis为什么快" tabindex="-1"><a class="header-anchor" href="#redis为什么快" aria-hidden="true">#</a> Redis为什么快</h2><p>Redis 内部做了非常多的性能优化，比较重要的有下面 3点：</p><ol><li>Redis 基于内存，内存的访问速度比磁盘快很多；</li><li>Redis 基于 Reactor 模式设计开发了一套高效的事件处理模型，主要是单线程事件循环和 IO 多路复用（Redis 线程模式后面会详细介绍到）；</li><li>Redis 内置了多种优化过后的数据类型/结构实现，性能非常高。</li></ol><p>一般像 MySQL 这类的数据库的 QPS 大概都在 4k 左右（4 核 8g） ，但是使用 Redis 缓存之后很容易达到 5w+，甚至能达到 10w+（就单机 Redis 的情况，Redis 集群的话会更高）。</p><h2 id="_3种常用的缓存读写策略详解" tabindex="-1"><a class="header-anchor" href="#_3种常用的缓存读写策略详解" aria-hidden="true">#</a> 3种常用的缓存读写策略详解</h2><h3 id="cache-aside-pattern-旁路缓存模式" tabindex="-1"><a class="header-anchor" href="#cache-aside-pattern-旁路缓存模式" aria-hidden="true">#</a> Cache Aside Pattern（旁路缓存模式）</h3><p><strong>Cache Aside Pattern 是我们平时使用比较多的一个缓存读写模式，比较适合读请求比较多的场景。</strong></p><p>Cache Aside Pattern 中服务端需要同时维系 db 和 cache，并且是以 db 的结果为准。</p><p>下面我们来看一下这个策略模式下的缓存读写步骤。</p><p><strong>写</strong>：</p><ul><li>先更新 db</li><li>然后直接删除 cache 。</li></ul><p><strong>读</strong> :</p><ul><li>从 cache 中读取数据，读取到就直接返回</li><li>cache 中读取不到的话，就从 db 中读取数据返回</li><li>再把数据放到 cache 中。</li></ul><p>你仅仅了解了上面这些内容的话是远远不够的，我们还要搞懂其中的原理。</p><p>比如说面试官很可能会追问：“<strong>在写数据的过程中，可以先删除 cache ，后更新 db 么？</strong>”</p><p><strong>答案：</strong> 那肯定是不行的！因为这样可能会造成 <strong>数据库（db）和缓存（Cache）数据不一致</strong>的问题。</p><p>举例：请求 1 先写数据 A，请求 2 随后读数据 A 的话，就很有可能产生数据不一致性的问题。</p><p>这个过程可以简单描述为：</p><blockquote><p>请求 1 先把 cache 中的 A 数据删除 -&gt; 请求 2 从 db 中读取数据-&gt;请求 1 再把 db 中的 A 数据更新</p></blockquote><p>当你这样回答之后，面试官可能会紧接着就追问：“<strong>在写数据的过程中，先更新 db，后删除 cache 就没有问题了么？</strong>”</p><p><strong>答案：</strong> 理论上来说还是可能会出现数据不一致性的问题，不过概率非常小，因为缓存的写入速度是比数据库的写入速度快很多。</p><p>举例：请求 1 先读数据 A，请求 2 随后写数据 A，并且数据 A 在请求 1 请求之前不在缓存中的话，也有可能产生数据不一致性的问题。</p><p>这个过程可以简单描述为：</p><blockquote><p>请求 1 从 db 读数据 A-&gt; 请求 2 更新 db 中的数据 A（此时缓存中无数据 A ，故不用执行删除缓存操作 ） -&gt; 请求 1 将数据 A 写入 cache</p></blockquote><p>现在我们再来分析一下 <strong>Cache Aside Pattern 的缺陷</strong>。</p><p><strong>缺陷 1：首次请求数据一定不在 cache 的问题</strong></p><p>解决办法：可以将热点数据可以提前放入 cache 中。</p><p><strong>缺陷 2：写操作比较频繁的话导致 cache 中的数据会被频繁被删除，这样会影响缓存命中率 。</strong></p><p>解决办法：</p><ul><li>数据库和缓存数据强一致场景：更新 db 的时候同样更新 cache，不过我们需要加一个锁/分布式锁来保证更新 cache 的时候不存在线程安全问题。</li><li>可以短暂地允许数据库和缓存数据不一致的场景：更新 db 的时候同样更新 cache，但是给缓存加一个比较短的过期时间，这样的话就可以保证即使数据不一致的话影响也比较小。</li></ul><h3 id="read-write-through-pattern-读写穿透" tabindex="-1"><a class="header-anchor" href="#read-write-through-pattern-读写穿透" aria-hidden="true">#</a> Read/Write Through Pattern（读写穿透）</h3><p>Read/Write Through Pattern 中服务端把 cache 视为主要数据存储，从中读取数据并将数据写入其中。cache 服务负责将此数据读取和写入 db，从而减轻了应用程序的职责。</p><p>这种缓存读写策略小伙伴们应该也发现了在平时在开发过程中非常少见。抛去性能方面的影响，大概率是因为我们经常使用的分布式缓存 Redis 并没有提供 cache 将数据写入 db 的功能。</p><p><strong>写（Write Through）：</strong></p><ul><li>先查 cache，cache 中不存在，直接更新 db。</li><li>cache 中存在，则先更新 cache，然后 cache 服务自己更新 db（<strong>同步更新 cache 和 db</strong>）。</li></ul><p><strong>读(Read Through)：</strong></p><ul><li>从 cache 中读取数据，读取到就直接返回 。</li><li>读取不到的话，先从 db 加载，写入到 cache 后返回响应。</li></ul><p>Read-Through Pattern 实际只是在 Cache-Aside Pattern 之上进行了封装。在 Cache-Aside Pattern 下，发生读请求的时候，如果 cache 中不存在对应的数据，是由客户端自己负责把数据写入 cache，而 Read Through Pattern 则是 cache 服务自己来写入缓存的，这对客户端是透明的。</p><p>和 Cache Aside Pattern 一样， Read-Through Pattern 也有首次请求数据一定不再 cache 的问题，对于热点数据可以提前放入缓存中。</p><h3 id="write-behind-pattern-异步缓存写入" tabindex="-1"><a class="header-anchor" href="#write-behind-pattern-异步缓存写入" aria-hidden="true">#</a> Write Behind Pattern（异步缓存写入）</h3><p>Write Behind Pattern 和 Read/Write Through Pattern 很相似，两者都是由 cache 服务来负责 cache 和 db 的读写。</p><p>但是，两个又有很大的不同：<strong>Read/Write Through 是同步更新 cache 和 db，而 Write Behind 则是只更新缓存，不直接更新 db，而是改为异步批量的方式来更新 db。</strong></p><p>很明显，这种方式对数据一致性带来了更大的挑战，比如 cache 数据可能还没异步更新 db 的话，cache 服务可能就就挂掉了。</p><p>这种策略在我们平时开发过程中也非常非常少见，但是不代表它的应用场景少，比如消息队列中消息的异步写入磁盘、MySQL 的 Innodb Buffer Pool 机制都用到了这种策略。</p><p>Write Behind Pattern 下 db 的写性能非常高，非常适合一些数据经常变化又对数据一致性要求没那么高的场景，比如浏览量、点赞量。</p><h2 id="redis的数据类型" tabindex="-1"><a class="header-anchor" href="#redis的数据类型" aria-hidden="true">#</a> Redis的数据类型</h2><h3 id="redis-常用的数据类型有哪些" tabindex="-1"><a class="header-anchor" href="#redis-常用的数据类型有哪些" aria-hidden="true">#</a> Redis 常用的数据类型有哪些？</h3><p>Redis 中比较常见的数据类型有下面这些：</p><ul><li><strong>5 种基础数据类型</strong>：String（字符串）、List（列表）、Set（集合）、Hash（散列）、Zset（有序集合）。</li><li><strong>3 种特殊数据类型</strong>：HyperLogLog（基数统计）、Bitmap （位图）、Geospatial (地理位置)。</li></ul><h3 id="string-的底层实现是什么" tabindex="-1"><a class="header-anchor" href="#string-的底层实现是什么" aria-hidden="true">#</a> String 的底层实现是什么？</h3><p>Redis 是基于 C 语言编写的，但 Redis 的 String 类型的底层实现并不是 C 语言中的字符串（即以空字符 <code>\\0</code> 结尾的字符数组），而是自己编写了 SDS（Simple Dynamic String，简单动态字符串） 来作为底层实现。</p><p>SDS 最早是 Redis 作者为日常 C 语言开发而设计的 C 字符串，后来被应用到了 Redis 上，并经过了大量的修改完善以适合高性能操作。</p><p>SDS 相比于 C 语言中的字符串有如下提升：</p><ol><li><strong>可以避免缓冲区溢出</strong>：C 语言中的字符串被修改（比如拼接）时，一旦没有分配足够长度的内存空间，就会造成缓冲区溢出。SDS 被修改时，会先根据 len 属性检查空间大小是否满足要求，如果不满足，则先扩展至所需大小再进行修改操作。</li><li><strong>获取字符串长度的复杂度较低</strong>：C 语言中的字符串的长度通常是经过遍历计数来实现的，时间复杂度为 O(n)。SDS 的长度获取直接读取 len 属性即可，时间复杂度为 O(1)。</li><li><strong>减少内存分配次数</strong>：为了避免修改（增加/减少）字符串时，每次都需要重新分配内存（C 语言的字符串是这样的），SDS 实现了空间预分配和惰性空间释放两种优化策略。当 SDS 需要增加字符串时，Redis 会为 SDS 分配好内存，并且根据特定的算法分配多余的内存，这样可以减少连续执行字符串增长操作所需的内存重分配次数。当 SDS 需要减少字符串时，这部分内存不会立即被回收，会被记录下来，等待后续使用（支持手动释放，有对应的 API）。</li><li><strong>二进制安全</strong>：C 语言中的字符串以空字符 <code>\\0</code> 作为字符串结束的标识，这存在一些问题，像一些二进制文件（比如图片、视频、音频）就可能包括空字符，C 字符串无法正确保存。SDS 使用 len 属性判断字符串是否结束，不存在这个问题。</li></ol><h3 id="string-还是-hash-存储对象数据更好呢" tabindex="-1"><a class="header-anchor" href="#string-还是-hash-存储对象数据更好呢" aria-hidden="true">#</a> String 还是 Hash 存储对象数据更好呢？</h3><ul><li>String 存储的是序列化后的对象数据，存放的是整个对象。Hash 是对对象的每个字段单独存储，可以获取部分字段的信息，也可以修改或者添加部分字段，节省网络流量。如果对象中某些字段需要经常变动或者经常需要单独查询对象中的个别字段信息，Hash 就非常适合。</li><li>String 存储相对来说更加节省内存，缓存相同数量的对象数据，String 消耗的内存约是 Hash 的一半。并且，存储具有多层嵌套的对象时也方便很多。如果系统对性能和资源消耗非常敏感的话，String 就非常适合。</li></ul><p>在绝大部分情况，我们建议使用 String 来存储对象数据即可！</p><h3 id="redis-的有序集合底层为什么要用跳表" tabindex="-1"><a class="header-anchor" href="#redis-的有序集合底层为什么要用跳表" aria-hidden="true">#</a> Redis 的有序集合底层为什么要用跳表</h3><p>而不用平衡树、红黑树或者 B+树：</p><ul><li>平衡树 vs 跳表：平衡树的插入、删除和查询的时间复杂度和跳表一样都是 <strong>O(log n)</strong>。对于范围查询来说，平衡树也可以通过中序遍历的方式达到和跳表一样的效果。但是它的每一次插入或者删除操作都需要保证整颗树左右节点的绝对平衡，只要不平衡就要通过旋转操作来保持平衡，这个过程是比较耗时的。跳表诞生的初衷就是为了克服平衡树的一些缺点。<strong>跳表使用概率平衡而不是严格强制的平衡，因此，跳表中的插入和删除算法比平衡树的等效算法简单得多，速度也快得多。</strong></li><li>红黑树 vs 跳表：相比较于红黑树来说，跳表的实现也更简单一些，不需要通过旋转和染色（红黑变换）来保证黑平衡。并且，按照区间来查找数据这个操作，红黑树的效率没有跳表高。</li><li>B+树 vs 跳表：B+树更适合作为数据库和文件系统中常用的索引结构之一，它的核心思想是通过可能少的 IO 定位到尽可能多的索引来获得查询数据。对于 Redis 这种内存数据库来说，它对这些并不感冒，因为 Redis 作为内存数据库它不可能存储大量的数据，所以对于索引不需要通过 B+树这种方式进行维护，只需按照概率进行随机维护即可，节约内存。而且使用跳表实现 zset 时相较前者来说更简单一些，在进行插入时只需通过索引将数据插入到链表中合适的位置再随机维护一定高度的索引即可，也不需要像 B+树那样插入时发现失衡时还需要对节点分裂与合并。</li></ul><h2 id="redis线程模型" tabindex="-1"><a class="header-anchor" href="#redis线程模型" aria-hidden="true">#</a> Redis线程模型</h2><p>对于读写命令来说，Redis 一直是单线程模型。不过，在 Redis 4.0 版本之后引入了多线程来执行一些大键值对的异步删除操作， Redis 6.0 版本之后引入了多线程来处理网络请求（提高网络 IO 读写性能）。</p><h2 id="redis事务" tabindex="-1"><a class="header-anchor" href="#redis事务" aria-hidden="true">#</a> Redis事务</h2><h3 id="redis-事务支持原子性吗" tabindex="-1"><a class="header-anchor" href="#redis-事务支持原子性吗" aria-hidden="true">#</a> Redis 事务支持原子性吗？</h3><p>Redis 的事务和我们平时理解的关系型数据库的事务不同。Redis 事务在运行错误的情况下，除了执行过程中出现错误的命令外，其他命令都能正常执行。并且，Redis 事务是不支持回滚（roll back）操作的。因此，Redis 事务其实是不满足原子性的。</p><p>Redis 官网也解释了自己为啥不支持回滚。简单来说就是 Redis 开发者们觉得没必要支持回滚，这样更简单便捷并且性能更好。Redis 开发者觉得即使命令执行错误也应该在开发过程中就被发现而不是生产过程中。</p><h3 id="redis-事务支持持久性吗" tabindex="-1"><a class="header-anchor" href="#redis-事务支持持久性吗" aria-hidden="true">#</a> Redis 事务支持持久性吗？</h3><p>Redis 不同于 Memcached 的很重要一点就是，Redis 支持持久化，而且支持 3 种持久化方式:</p><ul><li>快照（snapshotting，RDB）</li><li>只追加文件（append-only file, AOF）</li><li>RDB 和 AOF 的混合持久化(Redis 4.0 新增)</li></ul><p>与 RDB 持久化相比，AOF 持久化的实时性更好。在 Redis 的配置文件中存在三种不同的 AOF 持久化方式（ <code>fsync</code>策略），它们分别是：</p><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code>appendfsync always    <span class="token comment">#每次有数据修改发生时都会调用fsync函数同步AOF文件,fsync完成后线程返回,这样会严重降低Redis的速度</span>
appendfsync everysec  <span class="token comment">#每秒钟调用fsync函数同步一次AOF文件</span>
appendfsync no        <span class="token comment">#让操作系统决定何时进行同步，一般为30秒一次</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>AOF 持久化的<code>fsync</code>策略为 no、everysec 时都会存在数据丢失的情况 。always 下可以基本是可以满足持久性要求的，但性能太差，实际开发过程中不会使用。</p><p>因此，Redis 事务的持久性也是没办法保证的。</p><h3 id="如何解决-redis-事务的缺陷" tabindex="-1"><a class="header-anchor" href="#如何解决-redis-事务的缺陷" aria-hidden="true">#</a> 如何解决 Redis 事务的缺陷？</h3><p>Redis 从 2.6 版本开始支持执行 Lua 脚本，它的功能和事务非常类似。我们可以利用 Lua 脚本来批量执行多条 Redis 命令，这些 Redis 命令会被提交到 Redis 服务器一次性执行完成，大幅减小了网络开销。</p><p>一段 Lua 脚本可以视作一条命令执行，一段 Lua 脚本执行过程中不会有其他脚本或 Redis 命令同时执行，保证了操作不会被其他指令插入或打扰。</p><p>不过，如果 Lua 脚本运行时出错并中途结束，出错之后的命令是不会被执行的。并且，出错之前执行的命令是无法被撤销的，无法实现类似关系型数据库执行失败可以回滚的那种原子性效果。因此， <strong>严格来说的话，通过 Lua 脚本来批量执行 Redis 命令实际也是不完全满足原子性的。</strong></p><p>如果想要让 Lua 脚本中的命令全部执行，必须保证语句语法和命令都是对的。</p><p>另外，Redis 7.0 新增了 Redis functions 特性，你可以将 Redis functions 看作是比 Lua 更强大的脚本。</p><h2 id="redis性能优化" tabindex="-1"><a class="header-anchor" href="#redis性能优化" aria-hidden="true">#</a> Redis性能优化</h2><h3 id="使用批量操作减少网络传输" tabindex="-1"><a class="header-anchor" href="#使用批量操作减少网络传输" aria-hidden="true">#</a> 使用批量操作减少网络传输</h3><p>一个 Redis 命令的执行可以简化为以下 4 步：</p><ol><li>发送命令</li><li>命令排队</li><li>命令执行</li><li>返回结果</li></ol><p>其中，第 1 步和第 4 步耗费时间之和称为 <strong>Round Trip Time (RTT,往返时间)</strong> ，也就是数据在网络上传输的时间。</p><p>使用批量操作可以减少网络传输次数，进而有效减小网络开销，大幅减少 RTT。</p><p>另外，除了能减少 RTT 之外，发送一次命令的 socket I/O 成本也比较高（涉及上下文切换，存在<code>read()</code>和<code>write()</code>系统调用），批量操作还可以减少 socket I/O 成本。这个在官方对 pipeline 的介绍中有提到：https://redis.io/docs/manual/pipelining/。</p><h4 id="原生批量操作命令" tabindex="-1"><a class="header-anchor" href="#原生批量操作命令" aria-hidden="true">#</a> 原生批量操作命令</h4><p>Redis 中有一些原生支持批量操作的命令，比如：</p><ul><li><code>MGET</code>(获取一个或多个指定 key 的值)、<code>MSET</code>(设置一个或多个指定 key 的值)、</li><li><code>HMGET</code>(获取指定哈希表中一个或者多个指定字段的值)、<code>HMSET</code>(同时将一个或多个 field-value 对设置到指定哈希表中)、</li><li><code>SADD</code>（向指定集合添加一个或多个元素）</li><li>……</li></ul><p>不过，在 Redis 官方提供的分片集群解决方案 Redis Cluster 下，使用这些原生批量操作命令可能会存在一些小问题需要解决。就比如说 <code>MGET</code> 无法保证所有的 key 都在同一个 <strong>hash slot</strong>（哈希槽）上，<code>MGET</code>可能还是需要多次网络传输，原子操作也无法保证了。不过，相较于非批量操作，还是可以节省不少网络传输次数。</p><p>整个步骤的简化版如下（通常由 Redis 客户端实现，无需我们自己再手动实现）：</p><ol><li>找到 key 对应的所有 hash slot；</li><li>分别向对应的 Redis 节点发起 <code>MGET</code> 请求获取数据；</li><li>等待所有请求执行结束，重新组装结果数据，保持跟入参 key 的顺序一致，然后返回结果。</li></ol><p>如果想要解决这个多次网络传输的问题，比较常用的办法是自己维护 key 与 slot 的关系。不过这样不太灵活，虽然带来了性能提升，但同样让系统复杂性提升。</p><h4 id="lua-脚本" tabindex="-1"><a class="header-anchor" href="#lua-脚本" aria-hidden="true">#</a> Lua 脚本</h4><p>Lua 脚本同样支持批量操作多条命令。一段 Lua 脚本可以视作一条命令执行，可以看作是 <strong>原子操作</strong> 。也就是说，一段 Lua 脚本执行过程中不会有其他脚本或 Redis 命令同时执行，保证了操作不会被其他指令插入或打扰，这是 pipeline 所不具备的。</p><p>并且，Lua 脚本中支持一些简单的逻辑处理比如使用命令读取值并在 Lua 脚本中进行处理，这同样是 pipeline 所不具备的。</p><p>不过， Lua 脚本依然存在下面这些缺陷：</p><ul><li>如果 Lua 脚本运行时出错并中途结束，之后的操作不会进行，但是之前已经发生的写操作不会撤销，所以即使使用了 Lua 脚本，也不能实现类似数据库回滚的原子性。</li><li>Redis Cluster 下 Lua 脚本的原子操作也无法保证了，原因同样是无法保证所有的 key 都在同一个 <strong>hash slot</strong>（哈希槽）上。</li></ul><h3 id="大量-key-集中过期问题" tabindex="-1"><a class="header-anchor" href="#大量-key-集中过期问题" aria-hidden="true">#</a> 大量 key 集中过期问题</h3><p>我在前面提到过：对于过期 key，Redis 采用的是 <strong>定期删除+惰性/懒汉式删除</strong> 策略。</p><p>定期删除执行过程中，如果突然遇到大量过期 key 的话，客户端请求必须等待定期清理过期 key 任务线程执行完成，因为这个这个定期任务线程是在 Redis 主线程中执行的。这就导致客户端请求没办法被及时处理，响应速度会比较慢。</p><p><strong>如何解决呢？</strong> 下面是两种常见的方法：</p><ol><li>给 key 设置随机过期时间。</li><li>开启 lazy-free（惰性删除/延迟释放） 。lazy-free 特性是 Redis 4.0 开始引入的，指的是让 Redis 采用异步方式延迟释放 key 使用的内存，将该操作交给单独的子线程处理，避免阻塞主线程。</li></ol><p>个人建议不管是否开启 lazy-free，我们都尽量给 key 设置随机过期时间。</p>`,104)]))}const c=i(r,[["render",n],["__file","redis001.html.vue"]]);export{c as default};
